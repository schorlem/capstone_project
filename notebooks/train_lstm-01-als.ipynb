{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Train LSTM with word2vec embeddings </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I would like to mention these two excellent posts: \n",
    "\n",
    "https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "\n",
    "My solution is in part based on these two guidelines.\n",
    "\n",
    "Okay now let's import all of the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/andre/anaconda3/envs/capstone_project/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from unidecode import unidecode\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "from capstone_project import utility\n",
    "from capstone_project.models import neural_nets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set important constants and load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 30 # Maximum length of input for lstm the maximum number of tokens is 103 \n",
    "EMBEDDING_DIM = 300  # Length of the used word2vec implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_directory = \"../output/data/\"\n",
    "prefix = \"tokenized_\"\n",
    "\n",
    "train_data = utility.load_pickle(file_directory, prefix+\"train_data.pkl\")\n",
    "val_data = utility.load_pickle(file_directory, prefix+\"val_data.pkl\")  # Validation data set used to compare different classification algorithms\n",
    "train_y = train_data[\"is_duplicate\"].values\n",
    "val_y = val_data[\"is_duplicate\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_tokens</th>\n",
       "      <th>q2_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355802</th>\n",
       "      <td>355802</td>\n",
       "      <td>696825</td>\n",
       "      <td>696826</td>\n",
       "      <td>Which are the best songs of Enrique Iglesias?</td>\n",
       "      <td>Which is the best song of Enrique iglesias?</td>\n",
       "      <td>1</td>\n",
       "      <td>[good, song, enrique, iglesias]</td>\n",
       "      <td>[good, song, enrique, iglesias]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                                      question1  \\\n",
       "355802  355802  696825  696826  Which are the best songs of Enrique Iglesias?   \n",
       "\n",
       "                                          question2  is_duplicate  \\\n",
       "355802  Which is the best song of Enrique iglesias?             1   \n",
       "\n",
       "                              q1_tokens                        q2_tokens  \n",
       "355802  [good, song, enrique, iglesias]  [good, song, enrique, iglesias]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_data = train_data[:100]\n",
    "#val_data = val_data[:100]\n",
    "display(train_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the tokenized question as input for keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82267 unique tokens\n"
     ]
    }
   ],
   "source": [
    "# Decode again and join strings because keras tokenizer crashes when using unicode while spacy uses it\n",
    "#q1 = train_data[\"q1_tokens\"].apply(lambda x: unidecode(u\" \".join(x))).values\n",
    "#q2 = train_data[\"q2_tokens\"].apply(lambda x: unidecode(u\" \".join(x))).values\n",
    "q1 = train_data[\"question1\"].values\n",
    "q2 = train_data[\"question2\"].values\n",
    "\n",
    "all_questions = np.concatenate([q1, q2])\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_questions)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "number_words = len(word_index)+1  # Needed for embedding layer\n",
    "print(\"Found {} unique tokens\".format(len(word_index)))\n",
    "\n",
    "q1_sequences = tokenizer.texts_to_sequences(q1)\n",
    "q2_sequences = tokenizer.texts_to_sequences(q2)\n",
    "\n",
    "q1_data = pad_sequences(q1_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_data = pad_sequences(q2_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split second val and train set for validation at every epoch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doble the dataset size by switching the order of the questions. This is done in order to avoid symmetry issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into another training set and a second validation set \n",
    "# See: https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html and\n",
    "#indices = np.arange(q1_data.shape[0])\n",
    "#np.random.shuffle(indices)\n",
    "#q1_data = q1_data[indices]\n",
    "#q2_data = q2_data[indices]\n",
    "#labels = train_y[indices]\n",
    "\n",
    "#nb_validation_samples = int(0.1 * q1_data.shape[0])\n",
    "\n",
    "# Create subset for training with early stopping\n",
    "#q1_train = q1_data[:-nb_validation_samples]\n",
    "#q2_train = q1_data[:-nb_validation_samples]\n",
    "#train_labels = labels[:-nb_validation_samples]\n",
    "\n",
    "#create validation subset that is used to validate each epoch during training\n",
    "#q1_val_epochs = q1_data[-nb_validation_samples:]\n",
    "#q2_val_epochs = q2_data[-nb_validation_samples:]\n",
    "#val_epochs_labels = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kaggle ...\n",
    "#q12_train = np.concatenate((q1_train, q2_train), axis=0)\n",
    "#q21_train = np.concatenate((q2_train, q1_train), axis=0)\n",
    "#double_train_labels = np.concatenate((train_labels, train_labels), axis=0)\n",
    "\n",
    "#q12_val_epochs = np.concatenate((q1_val_epochs, q2_val_epochs), axis=0)\n",
    "#q21_val_epochs = np.concatenate((q2_val_epochs, q1_val_epochs), axis=0)\n",
    "#double_val_epochs_labels = np.concatenate((val_epochs_labels, val_epochs_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Credit: lstm kaggle\n",
    "VALIDATION_SPLIT = 0.1\n",
    "labels = train_y\n",
    "\n",
    "perm = np.random.permutation(len(q1_data))\n",
    "idx_train = perm[:int(len(q1_data)*(1-VALIDATION_SPLIT))]\n",
    "idx_val = perm[int(len(q1_data)*(1-VALIDATION_SPLIT)):]\n",
    "\n",
    "q12_train = np.concatenate((q1_data[idx_train], q2_data[idx_train]), axis=0)\n",
    "q21_train = np.concatenate((q2_data[idx_train], q1_data[idx_train]), axis=0)\n",
    "double_train_labels = np.concatenate((labels[idx_train], labels[idx_train]), axis=0)\n",
    "\n",
    "q12_val_epochs = np.concatenate((q1_data[idx_val], q2_data[idx_val]), axis=0)\n",
    "q21_val_epochs = np.concatenate((q2_data[idx_val], q1_data[idx_val]), axis=0)\n",
    "double_val_epochs_labels = np.concatenate((labels[idx_val], labels[idx_val]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create correct embeddings for validation data\n",
    "#q1_validation = val_data[\"q1_tokens\"].apply(lambda x: unidecode(u\" \".join(x))).values\n",
    "#q2_validation = val_data[\"q2_tokens\"].apply(lambda x: unidecode(u\" \".join(x))).values\n",
    "q1_validation = val_data[\"question1\"].values\n",
    "q2_validation = val_data[\"question2\"].values\n",
    "\n",
    "\n",
    "q1_val_sequences = tokenizer.texts_to_sequences(q1_validation)\n",
    "q2_val_sequences = tokenizer.texts_to_sequences(q2_validation)\n",
    "\n",
    "q1_val_data = pad_sequences(q1_val_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_val_data = pad_sequences(q2_val_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "val_labels = val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained word2vec model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Credit: https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "#import os\n",
    "#\n",
    "#embeddings_index = {}\n",
    "#f = open('../data/glove.42B.300d.txt')\n",
    "#for line in f:\n",
    "#    values = line.split()\n",
    "#    word = values[0]\n",
    "#    coefs = np.asarray(values[1:], dtype='float32')\n",
    "#    embeddings_index[word] = coefs\n",
    "#f.close()\n",
    "\n",
    "#print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Credit: https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "#embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "#for word, i in word_index.items():\n",
    "#    embedding_vector = embeddings_index.get(word)\n",
    "#    if embedding_vector is not None:\n",
    "#        # words not found in embedding index will be all-zeros.\n",
    "#        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\"../data/GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters of the lstm, create the emebedding matrix and create a keras model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 38543\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 30, 300)       24680400    input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 230)           488520      embedding_1[0][0]                \n",
      "                                                                   embedding_1[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 460)           0           lstm_1[0][0]                     \n",
      "                                                                   lstm_1[1][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 460)           1840        concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 460)           0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           59008       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 128)           512         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 128)           0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             129         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 25,230,409\n",
      "Trainable params: 548,833\n",
      "Non-trainable params: 24,681,576\n",
      "____________________________________________________________________________________________________\n",
      "230_0.30_128_0.30\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "nn_parameters = {\"max_sequence_length\": MAX_SEQUENCE_LENGTH,\n",
    "                 \"num_lstm\": 230,\n",
    "                 \"dropout_lstm\": 0.3,\n",
    "                 \"num_dense\": 128,\n",
    "                 \"dropout_dense\": 0.3}\n",
    "\n",
    "stamp = \"{}_{:.2f}_{}_{:.2f}\".format(nn_parameters[\"num_lstm\"], \n",
    "                                    nn_parameters[\"dropout_lstm\"],\n",
    "                                    nn_parameters[\"num_dense\"],\n",
    "                                    nn_parameters[\"dropout_dense\"])\n",
    "\n",
    "embedding_matrix = neural_nets.create_embedding_matrix(vec_model=word2vec_model, \n",
    "                                                       embedding_dim=EMBEDDING_DIM, \n",
    "                                                       word_index=word_index, \n",
    "                                                       number_words=number_words)\n",
    "\n",
    "model = neural_nets.create_lstm(embedding_matrix=embedding_matrix, \n",
    "                                embedding_dim=EMBEDDING_DIM, \n",
    "                                number_words=number_words, \n",
    "                                **nn_parameters)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
    "model.summary()\n",
    "print stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the data and check the performance on the second validation set every epoch. with early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 524036 samples, validate on 58228 samples\n",
      "Epoch 1/200\n",
      "524036/524036 [==============================] - 198s - loss: 0.5760 - acc: 0.7006 - val_loss: 0.5716 - val_acc: 0.6715\n",
      "Epoch 2/200\n",
      "524036/524036 [==============================] - 196s - loss: 0.5044 - acc: 0.7475 - val_loss: 0.4855 - val_acc: 0.7724\n",
      "Epoch 3/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.4707 - acc: 0.7683 - val_loss: 0.4522 - val_acc: 0.7812\n",
      "Epoch 4/200\n",
      "524036/524036 [==============================] - 196s - loss: 0.4475 - acc: 0.7829 - val_loss: 0.4325 - val_acc: 0.7947\n",
      "Epoch 5/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.4302 - acc: 0.7931 - val_loss: 0.4129 - val_acc: 0.8054\n",
      "Epoch 6/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.4165 - acc: 0.8009 - val_loss: 0.4185 - val_acc: 0.8027\n",
      "Epoch 7/200\n",
      "524036/524036 [==============================] - 196s - loss: 0.4044 - acc: 0.8085 - val_loss: 0.4089 - val_acc: 0.8084\n",
      "Epoch 8/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3936 - acc: 0.8144 - val_loss: 0.3978 - val_acc: 0.8140\n",
      "Epoch 9/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3844 - acc: 0.8197 - val_loss: 0.4015 - val_acc: 0.8107\n",
      "Epoch 10/200\n",
      "524036/524036 [==============================] - 196s - loss: 0.3773 - acc: 0.8233 - val_loss: 0.3944 - val_acc: 0.8159\n",
      "Epoch 11/200\n",
      "524036/524036 [==============================] - 196s - loss: 0.3696 - acc: 0.8274 - val_loss: 0.3836 - val_acc: 0.8230\n",
      "Epoch 12/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3626 - acc: 0.8318 - val_loss: 0.3911 - val_acc: 0.8192\n",
      "Epoch 13/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3575 - acc: 0.8342 - val_loss: 0.3851 - val_acc: 0.8218\n",
      "Epoch 14/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3509 - acc: 0.8381 - val_loss: 0.3862 - val_acc: 0.8204\n",
      "Epoch 15/200\n",
      "524036/524036 [==============================] - 196s - loss: 0.3465 - acc: 0.8405 - val_loss: 0.3812 - val_acc: 0.8242\n",
      "Epoch 16/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3402 - acc: 0.8435 - val_loss: 0.3827 - val_acc: 0.8255\n",
      "Epoch 17/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3367 - acc: 0.8459 - val_loss: 0.3846 - val_acc: 0.8228\n",
      "Epoch 18/200\n",
      "524036/524036 [==============================] - 196s - loss: 0.3332 - acc: 0.8478 - val_loss: 0.3796 - val_acc: 0.8243\n",
      "Epoch 19/200\n",
      "524036/524036 [==============================] - 196s - loss: 0.3292 - acc: 0.8503 - val_loss: 0.3775 - val_acc: 0.8265\n",
      "Epoch 20/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3255 - acc: 0.8520 - val_loss: 0.3802 - val_acc: 0.8274\n",
      "Epoch 21/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3222 - acc: 0.8537 - val_loss: 0.3847 - val_acc: 0.8257\n",
      "Epoch 22/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3184 - acc: 0.8557 - val_loss: 0.3781 - val_acc: 0.8279\n",
      "Epoch 23/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3164 - acc: 0.8565 - val_loss: 0.3740 - val_acc: 0.8323\n",
      "Epoch 24/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3131 - acc: 0.8588 - val_loss: 0.3766 - val_acc: 0.8300\n",
      "Epoch 25/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3111 - acc: 0.8597 - val_loss: 0.3879 - val_acc: 0.8257\n",
      "Epoch 26/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3084 - acc: 0.8608 - val_loss: 0.3792 - val_acc: 0.8318\n",
      "Epoch 27/200\n",
      "524036/524036 [==============================] - 195s - loss: 0.3059 - acc: 0.8623 - val_loss: 0.3781 - val_acc: 0.8309\n"
     ]
    }
   ],
   "source": [
    "# See https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "best_model_path = \"../output/models/lstm_val_epochs_\" + stamp + '.h5'\n",
    "model_checkpoint = ModelCheckpoint(best_model_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "hist = model.fit([q12_train, q21_train], double_train_labels,\n",
    "                 validation_data=([q12_val_epochs, q21_val_epochs], double_val_epochs_labels), \n",
    "                 epochs=200, batch_size=batch_size, shuffle=True,\n",
    "                 callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the complete train set using the number of epochs found above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO do stuff with hist\n",
    "\n",
    "#524036/524036 [==============================] - 194s - loss: 0.3470 - acc: 0.8404 - val_loss: 0.3801 - val_acc: 0.8247"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the trained model and calculate logloss and accuarcy on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%model = load_model(model_path)\n",
    "\n",
    "predictions = model.predict([q1_val_data, q2_val_data], batch_size=batch_size, verbose=1)\n",
    "predictions += model.predict([q2_val_data, q1_val_data], batch_size=batch_size, verbose=1)\n",
    "predictions /= 2\n",
    "\n",
    "loss = log_loss(val_y, predictions)\n",
    "acc = accuracy_score(val_y, np.rint(predictions))\n",
    "\n",
    "print \"Validation scores of Lstm model\\n LogLoss: {:.4f}\\n Accuracy: {:.2f} \".format(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create roc plot and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(val_y, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "lw = 2\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k', label='Luck')\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"../output/figures/lstm_roc_plot.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
