{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tutorials that I used: https://github.com/cytora/pycon-nlp-in-10-lines, https://nicschrading.com/project/Intro-to-NLP-with-spaCy/\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/andre/Documents/mooc/udacity/machinelearning/capstone_project/data/questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load egnlish models\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What\n",
      "What is the step by step guide to invest in share market in india?\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "text = data.question1.iloc[0]\n",
    "doc = nlp(unicode(text))\n",
    "token = doc[0]\n",
    "print token \n",
    "\n",
    "# Print sentences (one sentence per line)\n",
    "for sent in doc.sents:\n",
    "    print sent\n",
    "    \n",
    "print doc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What - NOUN\n",
      "is - VERB\n",
      "the - DET\n",
      "step - NOUN\n",
      "by - ADP\n",
      "step - NOUN\n",
      "guide - NOUN\n",
      "to - PART\n",
      "invest - VERB\n",
      "in - ADP\n",
      "share - NOUN\n",
      "market - NOUN\n",
      "in - ADP\n",
      "india - NOUN\n",
      "? - PUNCT\n"
     ]
    }
   ],
   "source": [
    "# For each token, print corresponding part of speech tag\n",
    "for token in doc:\n",
    "    print '{} - {}'.format(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What --> [What, is]\n",
      "is --> []\n",
      "the --> [the, step, step, invest, invest, is]\n",
      "step --> [step, invest, invest, is]\n",
      "by --> [by, step, step, invest, invest, is]\n",
      "step --> [step, guide, guide, by, by, step, step, invest, invest, is]\n",
      "guide --> [guide, by, by, step, step, invest, invest, is]\n",
      "to --> [to, invest, invest, is]\n",
      "invest --> [invest, is]\n",
      "in --> [in, invest, invest, is]\n",
      "share --> [share, market, market, in, in, invest, invest, is]\n",
      "market --> [market, in, in, invest, invest, is]\n",
      "in --> [in, invest, invest, is]\n",
      "india --> [india, in, in, invest, invest, is]\n",
      "? --> [?, is]\n",
      "What-attr-> is-ROOT\n",
      "\n",
      "the-det-> step-nsubj-> step-nsubj-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "step-nsubj-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "by-prep-> step-nsubj-> step-nsubj-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "step-compound-> guide-pobj-> guide-pobj-> by-prep-> by-prep-> step-nsubj-> step-nsubj-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "guide-pobj-> by-prep-> by-prep-> step-nsubj-> step-nsubj-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "to-aux-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "invest-ccomp-> is-ROOT\n",
      "in-prep-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "share-compound-> market-pobj-> market-pobj-> in-prep-> in-prep-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "market-pobj-> in-prep-> in-prep-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "in-prep-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "india-pobj-> in-prep-> in-prep-> invest-ccomp-> invest-ccomp-> is-ROOT\n",
      "?-punct-> is-ROOT\n"
     ]
    }
   ],
   "source": [
    "# Write a function that walks up the syntactic tree of the given token and collects all tokens to the root token (including root token).\n",
    "\n",
    "def tokens_to_root(token):\n",
    "    \"\"\"\n",
    "    Walk up the syntactic tree, collecting tokens to the root of the given `token`.\n",
    "    :param token: Spacy token\n",
    "    :return: list of Spacy tokens\n",
    "    \"\"\"\n",
    "    tokens_to_r = []\n",
    "    while token.head is not token:\n",
    "        tokens_to_r.append(token)\n",
    "        token = token.head\n",
    "        tokens_to_r.append(token)\n",
    "\n",
    "    return tokens_to_r\n",
    "\n",
    "# For every token in document, print it's tokens to the root\n",
    "for token in doc:\n",
    "    print '{} --> {}'.format(token, tokens_to_root(token))\n",
    "\n",
    "# Print dependency labels of the tokens\n",
    "for token in doc:\n",
    "    print '-> '.join(['{}-{}'.format(dependent_token, dependent_token.dep_) for dependent_token in tokens_to_root(token)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print all named entities with named entity types\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print '{} - {}'.format(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[What, the step, step guide, share market, india]\n"
     ]
    }
   ],
   "source": [
    "# Print noun chunks for doc\n",
    "print [chunk for chunk in doc.noun_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What , -7.22675800323\n",
      "is , -4.45774888992\n",
      "the , -3.52876663208\n",
      "step , -9.47515964508\n",
      "by , -6.37508678436\n",
      "step , -9.47515964508\n",
      "guide , -10.4972896576\n",
      "to , -3.85602164268\n",
      "invest , -10.917965889\n",
      "in , -4.61907196045\n",
      "share , -9.38536643982\n",
      "market , -9.18198680878\n",
      "in , -4.61907196045\n",
      "india , -13.3743810654\n",
      "? , -5.05924654007\n"
     ]
    }
   ],
   "source": [
    "# For every token in doc, print log-probability of the word, estimated from counts from a large corpus \n",
    "for token in doc:\n",
    "    print token, ',', token.prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.392899592931\n",
      "0.20734257731\n",
      "\n",
      "0.372411263216\n",
      "0.282086272624\n"
     ]
    }
   ],
   "source": [
    "# For a given document, calculate similarity between 'apples' and 'oranges' and 'boots' and 'hippos'\n",
    "doc2 = nlp(u\"Apples and oranges are similar. Boots and hippos aren't.\")\n",
    "apples = doc2[0]\n",
    "oranges = doc2[2]\n",
    "boots = doc2[6]\n",
    "hippos = doc2[8]\n",
    "print apples.similarity(oranges)\n",
    "print boots.similarity(hippos)\n",
    "\n",
    "print \"\"\n",
    "# Print similarity between sentence and word 'fruit'\n",
    "apples_sent, boots_sent = doc2.sents\n",
    "fruit = doc2.vocab[u'fruit']\n",
    "print apples_sent.similarity(fruit)\n",
    "print boots_sent.similarity(fruit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print spacy.en.STOPWORDS\n",
    "#print set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What   True what what\n",
      "is   True be be\n",
      "the   True the the\n",
      "step   False step step\n",
      "by   True by by\n",
      "step   False step step\n",
      "guide   False guide guide\n",
      "to   True to to\n",
      "invest   False invest invest\n",
      "in   True in in\n",
      "share   False share share\n",
      "market   False market market\n",
      "in   True in in\n",
      "india   False india india\n",
      "?   False ? ?\n"
     ]
    }
   ],
   "source": [
    "# remove stop words and print tokens\n",
    "\n",
    "\n",
    "for token in doc:\n",
    "    print token, \" \", token.is_stop, token.lemma_, token.lemma_.lower()\n",
    "\n",
    "#for token in doc:\n",
    "#    if not token.is_stop:\n",
    "#        print token"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
