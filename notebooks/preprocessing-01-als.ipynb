{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29a63be67fe43298d5526299a7c8b30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim\n",
    "from IPython.display import display\n",
    "from engarde.decorators import has_dtypes\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm_notebook\n",
    "from capstone_project import preprocessor\n",
    "\n",
    "tqdm_notebook().pandas(desc=\"Progress:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure that the loaded dataframe has the correct layout otherwise throw assertion error \n",
    "@has_dtypes(dict(question1=object, question2=object, is_duplicate=int))\n",
    "def load_data(filename):\n",
    "    \"\"\"Load dataframe using filename as input. A pandas dataframe is returned and it is checked that it \n",
    "    has the correct layout.\n",
    "    \"\"\"\n",
    "    df = pd.read_pickle(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "(None, <function _new_Index at 0x7f7f76a16c80>, (<class 'pandas.indexes.base.Index'>, {'data': array(['id', 'qid1', 'qid2', 'is_duplicate'], dtype=object), 'name': None}))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c66147d82e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../output/data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_directory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"train_data.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#train_data = train_data[0:5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andre/software/anaconda3/envs/capstone_project/lib/python2.7/site-packages/engarde/decorators.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8f7bdbde2889>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andre/software/anaconda3/envs/capstone_project/lib/python2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andre/software/anaconda3/envs/capstone_project/lib/python2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# reg/patched pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andre/software/anaconda3/envs/capstone_project/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36m_new_Index\u001b[0;34m(cls, d)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_new_Index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \"\"\" This is called upon unpickling, rather than the default which doesn't\n\u001b[1;32m     87\u001b[0m     \u001b[0mhave\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbreaks\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: (None, <function _new_Index at 0x7f7f76a16c80>, (<class 'pandas.indexes.base.Index'>, {'data': array(['id', 'qid1', 'qid2', 'is_duplicate'], dtype=object), 'name': None}))"
     ]
    }
   ],
   "source": [
    "# The current working directory for python is the capstone_project/notebook folder\n",
    "file_directory = \"../output/data/\"\n",
    "\n",
    "train_data = load_data(file_directory+\"train_data.pkl\")\n",
    "#train_data = train_data[0:5]\n",
    "\n",
    "test_data = load_data(file_directory+\"test_data.pkl\")\n",
    "#test_data = test_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.fillna(\"\", inplace=True)  # Two questions have empty fields\n",
    "train_data[\"q1_tokens\"] = train_data[\"question1\"].progress_apply(preprocessor.tokenize)\n",
    "train_data[\"q2_tokens\"] = train_data[\"question2\"].progress_apply(preprocessor.tokenize)\n",
    "\n",
    "test_data.fillna(\"\", inplace=True)  # Two questions have empty fields\n",
    "test_data[\"q1_tokens\"] = test_data[\"question1\"].progress_apply(preprocessor.tokenize)\n",
    "test_data[\"q2_tokens\"] = test_data[\"question2\"].progress_apply(preprocessor.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66dbee6e83e749c7b5ae477a9e9d211a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6704dede79dc4dc48986416b4811c632"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8957d0d55c4bfab023d17ba35b99a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4889aa7858f44d7baa788fad23b67a50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806d747e84ca426c9d078ade90d0ddff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64e37aa239643b4a88444067fbd30f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe98b1befcc4d10b5f09267eb4a83d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b701e59eb442a4b959fda8ab9d7d9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data[\"q1_word2vec\"] = train_data[\"q1_tokens\"].progress_apply(lambda x: preprocessor.question_to_vector(x, model=word2vec_model))\n",
    "train_data[\"q1_vecsum\"] = train_data[\"q1_word2vec\"].progress_apply(preprocessor.sum_vectors)\n",
    "train_data.drop(\"q1_word2vec\", 1, inplace=True)\n",
    "\n",
    "train_data[\"q2_word2vec\"] = train_data[\"q2_tokens\"].progress_apply(lambda x: preprocessor.question_to_vector(x, model=word2vec_model))\n",
    "train_data[\"q2_vecsum\"] = train_data[\"q2_word2vec\"].progress_apply(preprocessor.sum_vectors)\n",
    "train_data.drop(\"q2_word2vec\", 1, inplace=True)\n",
    "\n",
    "\n",
    "test_data[\"q1_word2vec\"] = test_data[\"q1_tokens\"].progress_apply(lambda x: preprocessor.question_to_vector(x, model=word2vec_model))\n",
    "test_data[\"q1_vecsum\"] = test_data[\"q1_word2vec\"].progress_apply(preprocessor.sum_vectors)\n",
    "test_data.drop(\"q1_word2vec\", 1, inplace=True)\n",
    "\n",
    "\n",
    "test_data[\"q2_word2vec\"] = test_data[\"q2_tokens\"].progress_apply(lambda x: preprocessor.question_to_vector(x, model=word2vec_model))\n",
    "test_data[\"q2_vecsum\"] = test_data[\"q2_word2vec\"].progress_apply(preprocessor.sum_vectors)\n",
    "test_data.drop(\"q2_word2vec\", 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_tokens</th>\n",
       "      <th>q2_tokens</th>\n",
       "      <th>q1_vecsum</th>\n",
       "      <th>q2_vecsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218104</th>\n",
       "      <td>218104</td>\n",
       "      <td>430027</td>\n",
       "      <td>430028</td>\n",
       "      <td>How do I build a self confidence?</td>\n",
       "      <td>How can I raise my self esteem?</td>\n",
       "      <td>1</td>\n",
       "      <td>[build, self, confidence]</td>\n",
       "      <td>[raise, self, esteem]</td>\n",
       "      <td>[0.0182878, 0.0904482, 0.0239183, -0.00576562,...</td>\n",
       "      <td>[0.052301, 0.0498388, -0.0129904, 0.099338, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                          question1  \\\n",
       "218104  218104  430027  430028  How do I build a self confidence?   \n",
       "\n",
       "                              question2  is_duplicate  \\\n",
       "218104  How can I raise my self esteem?             1   \n",
       "\n",
       "                        q1_tokens              q2_tokens  \\\n",
       "218104  [build, self, confidence]  [raise, self, esteem]   \n",
       "\n",
       "                                                q1_vecsum  \\\n",
       "218104  [0.0182878, 0.0904482, 0.0239183, -0.00576562,...   \n",
       "\n",
       "                                                q2_vecsum  \n",
       "218104  [0.052301, 0.0498388, -0.0129904, 0.099338, -0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_tokens</th>\n",
       "      <th>q2_tokens</th>\n",
       "      <th>q1_vecsum</th>\n",
       "      <th>q2_vecsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113079</th>\n",
       "      <td>113079</td>\n",
       "      <td>224193</td>\n",
       "      <td>224194</td>\n",
       "      <td>What does horny goat weed do?</td>\n",
       "      <td>What is horny goat weed?</td>\n",
       "      <td>1</td>\n",
       "      <td>[horny, goat, weed]</td>\n",
       "      <td>[horny, goat, weed]</td>\n",
       "      <td>[0.0250831, 0.0553706, -0.048425, 0.0710079, -...</td>\n",
       "      <td>[0.0250831, 0.0553706, -0.048425, 0.0710079, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                      question1  \\\n",
       "113079  113079  224193  224194  What does horny goat weed do?   \n",
       "\n",
       "                       question2  is_duplicate            q1_tokens  \\\n",
       "113079  What is horny goat weed?             1  [horny, goat, weed]   \n",
       "\n",
       "                  q2_tokens  \\\n",
       "113079  [horny, goat, weed]   \n",
       "\n",
       "                                                q1_vecsum  \\\n",
       "113079  [0.0250831, 0.0553706, -0.048425, 0.0710079, -...   \n",
       "\n",
       "                                                q2_vecsum  \n",
       "113079  [0.0250831, 0.0553706, -0.048425, 0.0710079, -...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.head(1))\n",
    "display(test_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_as_pickle(dataset, output_dir, filename):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    with open (output_dir+filename, \"wb\") as handle:\n",
    "        pickle.dump(dataset, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = \"blaa\"\n",
    "\n",
    "save_as_pickle(train_data, file_directory, prefix+\"preprocessed_train_data.pkl\") \n",
    "save_as_pickle(test_data, file_directory, prefix+\"preprocessed_test_data.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, random_state=12574, shuffle=True)\n",
    "output_directory = \"../output/models/\"\n",
    "save_as_pickle(skf, output_directory, \"kfolds.pkl\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
